{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhR71rIxLlZtSDKPUC1ZHr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snpsuen/Deep_Learning_Data/blob/main/RNN_GBP_HKD_Daily_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "_-kL-Ar1SXre"
      },
      "outputs": [],
      "source": [
        "# lstm for time series forecasting\n",
        "import numpy\n",
        "from numpy import sqrt\n",
        "from numpy import asarray\n",
        "from pandas import read_csv\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps, select):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix, select], sequence[end_ix, select]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn asarray(X), asarray(y)"
      ],
      "metadata": {
        "id": "L3ppcARFS2Ea"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/snpsuen/Deep_Learning_Data/main/dataset/GBP_HKD_Historical_Data_20221201-20230303.csv'\n",
        "df = read_csv(path, header=0, index_col=0, squeeze=True)\n",
        "# extract price columns from loaded data frame\n",
        "df_prices = df.iloc[:, 0:4]\n",
        "# retrieve the values\n",
        "values = df_prices.values.astype('float32')\n",
        "# specify the window size\n",
        "n_steps = 10\n",
        "select = 0\n",
        "# split into samples\n",
        "X, y = split_sequence(values, n_steps, select)\n",
        "print(\"X = \", X)\n",
        "print(\"y = \", y)\n",
        "print(\"X.shape = %s, y.shape = %s\" %(X.shape, y.shape))\n",
        "# reshape into [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "# split into train/test\n",
        "n_test = 10\n",
        "X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\n",
        "print(\"After reshape, X_train.shape = %s, X_test.shape = %s, y_train.shape = %s, y_test.shape = %s\" %(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n",
        "print(\"X_test = \", X_test)\n",
        "print(\"y_test = \", y_test)\n",
        "input_shape = X.shape[1:]\n",
        "print(\"input_shape = \", input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdzYOEuxTEps",
        "outputId": "b78fd02e-dcc3-4ed6-d521-6a99c1585dd4"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X =  [[9.5229 9.5701 9.4667 9.4376 9.5049 9.5245 9.541  9.5415 9.6036 9.6546]\n",
            " [9.5701 9.4667 9.4376 9.5049 9.5245 9.541  9.5415 9.6036 9.6546 9.4689]\n",
            " [9.4667 9.4376 9.5049 9.5245 9.541  9.5415 9.6036 9.6546 9.4689 9.4492]\n",
            " [9.4376 9.5049 9.5245 9.541  9.5415 9.6036 9.6546 9.4689 9.4492 9.4512]\n",
            " [9.5049 9.5245 9.541  9.5415 9.6036 9.6546 9.4689 9.4492 9.4512 9.4857]\n",
            " [9.5245 9.541  9.5415 9.6036 9.6546 9.4689 9.4492 9.4512 9.4857 9.421 ]\n",
            " [9.541  9.5415 9.6036 9.6546 9.4689 9.4492 9.4512 9.4857 9.421  9.3873]\n",
            " [9.5415 9.6036 9.6546 9.4689 9.4492 9.4512 9.4857 9.421  9.3873 9.4102]\n",
            " [9.6036 9.6546 9.4689 9.4492 9.4512 9.4857 9.421  9.3873 9.4102 9.414 ]\n",
            " [9.6546 9.4689 9.4492 9.4512 9.4857 9.421  9.3873 9.4102 9.414  9.3769]\n",
            " [9.4689 9.4492 9.4512 9.4857 9.421  9.3873 9.4102 9.414  9.3769 9.3662]\n",
            " [9.4492 9.4512 9.4857 9.421  9.3873 9.4102 9.414  9.3769 9.3662 9.3959]\n",
            " [9.4512 9.4857 9.421  9.3873 9.4102 9.414  9.3769 9.3662 9.3959 9.4472]\n",
            " [9.4857 9.421  9.3873 9.4102 9.414  9.3769 9.3662 9.3959 9.4472 9.399 ]\n",
            " [9.421  9.3873 9.4102 9.414  9.3769 9.3662 9.3959 9.4472 9.399  9.3463]\n",
            " [9.3873 9.4102 9.414  9.3769 9.3662 9.3959 9.4472 9.399  9.3463 9.4206]\n",
            " [9.4102 9.414  9.3769 9.3662 9.3959 9.4472 9.399  9.3463 9.4206 9.3032]\n",
            " [9.414  9.3769 9.3662 9.3959 9.4472 9.399  9.3463 9.4206 9.3032 9.4393]\n",
            " [9.3769 9.3662 9.3959 9.4472 9.399  9.3463 9.4206 9.3032 9.4393 9.5069]\n",
            " [9.3662 9.3959 9.4472 9.399  9.3463 9.4206 9.3032 9.4393 9.5069 9.491 ]\n",
            " [9.3959 9.4472 9.399  9.3463 9.4206 9.3032 9.4393 9.5069 9.491  9.4867]\n",
            " [9.4472 9.399  9.3463 9.4206 9.3032 9.4393 9.5069 9.491  9.4867 9.532 ]\n",
            " [9.399  9.3463 9.4206 9.3032 9.4393 9.5069 9.491  9.4867 9.532  9.5475]\n",
            " [9.3463 9.4206 9.3032 9.4393 9.5069 9.491  9.4867 9.532  9.5475 9.5219]\n",
            " [9.4206 9.3032 9.4393 9.5069 9.491  9.4867 9.532  9.5475 9.5219 9.6044]\n",
            " [9.3032 9.4393 9.5069 9.491  9.4867 9.532  9.5475 9.5219 9.6044 9.6603]\n",
            " [9.4393 9.5069 9.491  9.4867 9.532  9.5475 9.5219 9.6044 9.6603 9.7005]\n",
            " [9.5069 9.491  9.4867 9.532  9.5475 9.5219 9.6044 9.6603 9.7005 9.7027]\n",
            " [9.491  9.4867 9.532  9.5475 9.5219 9.6044 9.6603 9.7005 9.7027 9.691 ]\n",
            " [9.4867 9.532  9.5475 9.5219 9.6044 9.6603 9.7005 9.7027 9.691  9.6563]\n",
            " [9.532  9.5475 9.5219 9.6044 9.6603 9.7005 9.7027 9.691  9.6563 9.7099]\n",
            " [9.5475 9.5219 9.6044 9.6603 9.7005 9.7027 9.691  9.6563 9.7099 9.7106]\n",
            " [9.5219 9.6044 9.6603 9.7005 9.7027 9.691  9.6563 9.7099 9.7106 9.7059]\n",
            " [9.6044 9.6603 9.7005 9.7027 9.691  9.6563 9.7099 9.7106 9.7059 9.678 ]\n",
            " [9.6603 9.7005 9.7027 9.691  9.6563 9.7099 9.7106 9.7059 9.678  9.659 ]\n",
            " [9.7005 9.7027 9.691  9.6563 9.7099 9.7106 9.7059 9.678  9.659  9.7058]\n",
            " [9.7027 9.691  9.6563 9.7099 9.7106 9.7059 9.678  9.659  9.7058 9.5878]\n",
            " [9.691  9.6563 9.7099 9.7106 9.7059 9.678  9.659  9.7058 9.5878 9.4562]\n",
            " [9.6563 9.7099 9.7106 9.7059 9.678  9.659  9.7058 9.5878 9.4562 9.4278]\n",
            " [9.7099 9.7106 9.7059 9.678  9.659  9.7058 9.5878 9.4562 9.4278 9.4543]\n",
            " [9.7106 9.7059 9.678  9.659  9.7058 9.5878 9.4562 9.4278 9.4543 9.4754]\n",
            " [9.7059 9.678  9.659  9.7058 9.5878 9.4562 9.4278 9.4543 9.4754 9.5154]\n",
            " [9.678  9.659  9.7058 9.5878 9.4562 9.4278 9.4543 9.4754 9.5154 9.4609]\n",
            " [9.659  9.7058 9.5878 9.4562 9.4278 9.4543 9.4754 9.5154 9.4609 9.5265]\n",
            " [9.7058 9.5878 9.4562 9.4278 9.4543 9.4754 9.5154 9.4609 9.5265 9.5533]\n",
            " [9.5878 9.4562 9.4278 9.4543 9.4754 9.5154 9.4609 9.5265 9.5533 9.4378]\n",
            " [9.4562 9.4278 9.4543 9.4754 9.5154 9.4609 9.5265 9.5533 9.4378 9.4131]\n",
            " [9.4278 9.4543 9.4754 9.5154 9.4609 9.5265 9.5533 9.4378 9.4131 9.441 ]\n",
            " [9.4543 9.4754 9.5154 9.4609 9.5265 9.5533 9.4378 9.4131 9.441  9.4308]\n",
            " [9.4754 9.5154 9.4609 9.5265 9.5533 9.4378 9.4131 9.441  9.4308 9.4997]\n",
            " [9.5154 9.4609 9.5265 9.5533 9.4378 9.4131 9.441  9.4308 9.4997 9.45  ]\n",
            " [9.4609 9.5265 9.5533 9.4378 9.4131 9.441  9.4308 9.4997 9.45   9.4264]\n",
            " [9.5265 9.5533 9.4378 9.4131 9.441  9.4308 9.4997 9.45   9.4264 9.372 ]\n",
            " [9.5533 9.4378 9.4131 9.441  9.4308 9.4997 9.45   9.4264 9.372  9.4614]\n",
            " [9.4378 9.4131 9.441  9.4308 9.4997 9.45   9.4264 9.372  9.4614 9.4346]\n",
            " [9.4131 9.441  9.4308 9.4997 9.45   9.4264 9.372  9.4614 9.4346 9.4406]\n",
            " [9.441  9.4308 9.4997 9.45   9.4264 9.372  9.4614 9.4346 9.4406 9.3731]]\n",
            "y =  [9.4689 9.4492 9.4512 9.4857 9.421  9.3873 9.4102 9.414  9.3769 9.3662\n",
            " 9.3959 9.4472 9.399  9.3463 9.4206 9.3032 9.4393 9.5069 9.491  9.4867\n",
            " 9.532  9.5475 9.5219 9.6044 9.6603 9.7005 9.7027 9.691  9.6563 9.7099\n",
            " 9.7106 9.7059 9.678  9.659  9.7058 9.5878 9.4562 9.4278 9.4543 9.4754\n",
            " 9.5154 9.4609 9.5265 9.5533 9.4378 9.4131 9.441  9.4308 9.4997 9.45\n",
            " 9.4264 9.372  9.4614 9.4346 9.4406 9.3731 9.4037]\n",
            "X.shape = (57, 10), y.shape = (57,)\n",
            "After reshape, X_train.shape = (47, 10, 1), X_test.shape = (10, 10, 1), y_train.shape = (47,), y_test.shape = (10,)\n",
            "X_test =  [[[9.4278]\n",
            "  [9.4543]\n",
            "  [9.4754]\n",
            "  [9.5154]\n",
            "  [9.4609]\n",
            "  [9.5265]\n",
            "  [9.5533]\n",
            "  [9.4378]\n",
            "  [9.4131]\n",
            "  [9.441 ]]\n",
            "\n",
            " [[9.4543]\n",
            "  [9.4754]\n",
            "  [9.5154]\n",
            "  [9.4609]\n",
            "  [9.5265]\n",
            "  [9.5533]\n",
            "  [9.4378]\n",
            "  [9.4131]\n",
            "  [9.441 ]\n",
            "  [9.4308]]\n",
            "\n",
            " [[9.4754]\n",
            "  [9.5154]\n",
            "  [9.4609]\n",
            "  [9.5265]\n",
            "  [9.5533]\n",
            "  [9.4378]\n",
            "  [9.4131]\n",
            "  [9.441 ]\n",
            "  [9.4308]\n",
            "  [9.4997]]\n",
            "\n",
            " [[9.5154]\n",
            "  [9.4609]\n",
            "  [9.5265]\n",
            "  [9.5533]\n",
            "  [9.4378]\n",
            "  [9.4131]\n",
            "  [9.441 ]\n",
            "  [9.4308]\n",
            "  [9.4997]\n",
            "  [9.45  ]]\n",
            "\n",
            " [[9.4609]\n",
            "  [9.5265]\n",
            "  [9.5533]\n",
            "  [9.4378]\n",
            "  [9.4131]\n",
            "  [9.441 ]\n",
            "  [9.4308]\n",
            "  [9.4997]\n",
            "  [9.45  ]\n",
            "  [9.4264]]\n",
            "\n",
            " [[9.5265]\n",
            "  [9.5533]\n",
            "  [9.4378]\n",
            "  [9.4131]\n",
            "  [9.441 ]\n",
            "  [9.4308]\n",
            "  [9.4997]\n",
            "  [9.45  ]\n",
            "  [9.4264]\n",
            "  [9.372 ]]\n",
            "\n",
            " [[9.5533]\n",
            "  [9.4378]\n",
            "  [9.4131]\n",
            "  [9.441 ]\n",
            "  [9.4308]\n",
            "  [9.4997]\n",
            "  [9.45  ]\n",
            "  [9.4264]\n",
            "  [9.372 ]\n",
            "  [9.4614]]\n",
            "\n",
            " [[9.4378]\n",
            "  [9.4131]\n",
            "  [9.441 ]\n",
            "  [9.4308]\n",
            "  [9.4997]\n",
            "  [9.45  ]\n",
            "  [9.4264]\n",
            "  [9.372 ]\n",
            "  [9.4614]\n",
            "  [9.4346]]\n",
            "\n",
            " [[9.4131]\n",
            "  [9.441 ]\n",
            "  [9.4308]\n",
            "  [9.4997]\n",
            "  [9.45  ]\n",
            "  [9.4264]\n",
            "  [9.372 ]\n",
            "  [9.4614]\n",
            "  [9.4346]\n",
            "  [9.4406]]\n",
            "\n",
            " [[9.441 ]\n",
            "  [9.4308]\n",
            "  [9.4997]\n",
            "  [9.45  ]\n",
            "  [9.4264]\n",
            "  [9.372 ]\n",
            "  [9.4614]\n",
            "  [9.4346]\n",
            "  [9.4406]\n",
            "  [9.3731]]]\n",
            "y_test =  [9.4308 9.4997 9.45   9.4264 9.372  9.4614 9.4346 9.4406 9.3731 9.4037]\n",
            "input_shape =  (10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the last 9 data points from X_test to form X_predict\n",
        "X_predict = X_test[-1][1:]\n",
        "# Extract the last y_test data point\n",
        "y_last = numpy.array([y_test[-1]])\n",
        "\n",
        "# Append y_last to the X_predict\n",
        "X_predict = numpy.append(X_predict, y_last)\n",
        "\n",
        "# Reshape X_predict to (1, 10, 1)\n",
        "X_predict = X_predict.reshape(1, X_predict.shape[0], 1)\n",
        "print(\"X_predict = \", X_predict)\n",
        "print(\"X_predict.shape = \", X_predict.shape)\n"
      ],
      "metadata": {
        "id": "zwWnBlC4OWeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8322164a-51cc-45ee-d0cb-774d29507c9b"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_predict =  [[[9.4308]\n",
            "  [9.4997]\n",
            "  [9.45  ]\n",
            "  [9.4264]\n",
            "  [9.372 ]\n",
            "  [9.4614]\n",
            "  [9.4346]\n",
            "  [9.4406]\n",
            "  [9.3731]\n",
            "  [9.4037]]]\n",
            "X_predict.shape =  (1, 10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "# model.add(LSTM(100, activation='relu', kernel_initializer='he_normal', input_shape=input_shape))\n",
        "model.add(LSTM(256, kernel_initializer='he_normal', input_shape=input_shape))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(64, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1JtkkT61Tn8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583fd3e2-ddbd-461a-e605-4d7b1afa75fd"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_15 (LSTM)              (None, 256)               264192    \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 305,409\n",
            "Trainable params: 305,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=40, batch_size=32, verbose=2, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ4OVN-wTtml",
        "outputId": "b9139d3f-07a5-46f6-c491-f0923e3ca494"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "2/2 - 4s - loss: 108.9638 - mae: 10.4324 - val_loss: 85.2663 - val_mae: 9.2339 - 4s/epoch - 2s/step\n",
            "Epoch 2/40\n",
            "2/2 - 0s - loss: 84.0908 - mae: 9.1670 - val_loss: 69.2657 - val_mae: 8.3225 - 117ms/epoch - 58ms/step\n",
            "Epoch 3/40\n",
            "2/2 - 0s - loss: 68.5388 - mae: 8.2755 - val_loss: 56.5133 - val_mae: 7.5174 - 98ms/epoch - 49ms/step\n",
            "Epoch 4/40\n",
            "2/2 - 0s - loss: 55.8569 - mae: 7.4697 - val_loss: 44.7502 - val_mae: 6.6895 - 117ms/epoch - 58ms/step\n",
            "Epoch 5/40\n",
            "2/2 - 0s - loss: 44.1967 - mae: 6.6437 - val_loss: 34.9925 - val_mae: 5.9153 - 123ms/epoch - 62ms/step\n",
            "Epoch 6/40\n",
            "2/2 - 0s - loss: 34.5496 - mae: 5.8746 - val_loss: 26.2639 - val_mae: 5.1247 - 112ms/epoch - 56ms/step\n",
            "Epoch 7/40\n",
            "2/2 - 0s - loss: 25.8390 - mae: 5.0784 - val_loss: 18.4851 - val_mae: 4.2993 - 103ms/epoch - 52ms/step\n",
            "Epoch 8/40\n",
            "2/2 - 0s - loss: 18.0676 - mae: 4.2444 - val_loss: 11.6340 - val_mae: 3.4107 - 103ms/epoch - 51ms/step\n",
            "Epoch 9/40\n",
            "2/2 - 0s - loss: 11.2780 - mae: 3.3475 - val_loss: 6.1603 - val_mae: 2.4817 - 100ms/epoch - 50ms/step\n",
            "Epoch 10/40\n",
            "2/2 - 0s - loss: 5.9088 - mae: 2.4196 - val_loss: 2.3714 - val_mae: 1.5395 - 106ms/epoch - 53ms/step\n",
            "Epoch 11/40\n",
            "2/2 - 0s - loss: 2.2359 - mae: 1.4764 - val_loss: 0.3403 - val_mae: 0.5821 - 114ms/epoch - 57ms/step\n",
            "Epoch 12/40\n",
            "2/2 - 0s - loss: 0.3427 - mae: 0.5214 - val_loss: 0.1203 - val_mae: 0.3448 - 97ms/epoch - 49ms/step\n",
            "Epoch 13/40\n",
            "2/2 - 0s - loss: 0.2137 - mae: 0.3849 - val_loss: 1.2573 - val_mae: 1.1207 - 116ms/epoch - 58ms/step\n",
            "Epoch 14/40\n",
            "2/2 - 0s - loss: 1.2916 - mae: 1.1188 - val_loss: 2.6312 - val_mae: 1.6217 - 106ms/epoch - 53ms/step\n",
            "Epoch 15/40\n",
            "2/2 - 0s - loss: 2.4770 - mae: 1.5686 - val_loss: 3.2820 - val_mae: 1.8112 - 106ms/epoch - 53ms/step\n",
            "Epoch 16/40\n",
            "2/2 - 0s - loss: 2.9498 - mae: 1.7127 - val_loss: 2.9936 - val_mae: 1.7298 - 112ms/epoch - 56ms/step\n",
            "Epoch 17/40\n",
            "2/2 - 0s - loss: 2.5886 - mae: 1.6024 - val_loss: 2.1905 - val_mae: 1.4796 - 147ms/epoch - 74ms/step\n",
            "Epoch 18/40\n",
            "2/2 - 0s - loss: 1.7920 - mae: 1.3318 - val_loss: 1.2350 - val_mae: 1.1107 - 216ms/epoch - 108ms/step\n",
            "Epoch 19/40\n",
            "2/2 - 0s - loss: 0.9376 - mae: 0.9538 - val_loss: 0.4832 - val_mae: 0.6941 - 156ms/epoch - 78ms/step\n",
            "Epoch 20/40\n",
            "2/2 - 0s - loss: 0.3145 - mae: 0.5388 - val_loss: 0.0865 - val_mae: 0.2917 - 160ms/epoch - 80ms/step\n",
            "Epoch 21/40\n",
            "2/2 - 0s - loss: 0.0445 - mae: 0.1684 - val_loss: 0.0045 - val_mae: 0.0563 - 163ms/epoch - 82ms/step\n",
            "Epoch 22/40\n",
            "2/2 - 0s - loss: 0.0518 - mae: 0.1926 - val_loss: 0.1041 - val_mae: 0.3206 - 163ms/epoch - 82ms/step\n",
            "Epoch 23/40\n",
            "2/2 - 0s - loss: 0.2087 - mae: 0.4387 - val_loss: 0.2417 - val_mae: 0.4903 - 162ms/epoch - 81ms/step\n",
            "Epoch 24/40\n",
            "2/2 - 0s - loss: 0.3664 - mae: 0.5925 - val_loss: 0.3192 - val_mae: 0.5638 - 172ms/epoch - 86ms/step\n",
            "Epoch 25/40\n",
            "2/2 - 0s - loss: 0.4385 - mae: 0.6513 - val_loss: 0.3046 - val_mae: 0.5506 - 174ms/epoch - 87ms/step\n",
            "Epoch 26/40\n",
            "2/2 - 0s - loss: 0.4066 - mae: 0.6264 - val_loss: 0.2206 - val_mae: 0.4682 - 181ms/epoch - 90ms/step\n",
            "Epoch 27/40\n",
            "2/2 - 0s - loss: 0.3013 - mae: 0.5352 - val_loss: 0.1144 - val_mae: 0.3361 - 178ms/epoch - 89ms/step\n",
            "Epoch 28/40\n",
            "2/2 - 0s - loss: 0.1719 - mae: 0.3981 - val_loss: 0.0326 - val_mae: 0.1767 - 193ms/epoch - 96ms/step\n",
            "Epoch 29/40\n",
            "2/2 - 0s - loss: 0.0709 - mae: 0.2369 - val_loss: 0.0015 - val_mae: 0.0330 - 197ms/epoch - 98ms/step\n",
            "Epoch 30/40\n",
            "2/2 - 0s - loss: 0.0229 - mae: 0.1154 - val_loss: 0.0204 - val_mae: 0.1380 - 180ms/epoch - 90ms/step\n",
            "Epoch 31/40\n",
            "2/2 - 0s - loss: 0.0202 - mae: 0.1254 - val_loss: 0.0659 - val_mae: 0.2540 - 175ms/epoch - 88ms/step\n",
            "Epoch 32/40\n",
            "2/2 - 0s - loss: 0.0471 - mae: 0.1900 - val_loss: 0.1088 - val_mae: 0.3278 - 156ms/epoch - 78ms/step\n",
            "Epoch 33/40\n",
            "2/2 - 0s - loss: 0.0762 - mae: 0.2473 - val_loss: 0.1284 - val_mae: 0.3564 - 113ms/epoch - 57ms/step\n",
            "Epoch 34/40\n",
            "2/2 - 0s - loss: 0.0867 - mae: 0.2686 - val_loss: 0.1183 - val_mae: 0.3420 - 112ms/epoch - 56ms/step\n",
            "Epoch 35/40\n",
            "2/2 - 0s - loss: 0.0762 - mae: 0.2486 - val_loss: 0.0882 - val_mae: 0.2946 - 105ms/epoch - 52ms/step\n",
            "Epoch 36/40\n",
            "2/2 - 0s - loss: 0.0543 - mae: 0.2027 - val_loss: 0.0527 - val_mae: 0.2264 - 117ms/epoch - 59ms/step\n",
            "Epoch 37/40\n",
            "2/2 - 0s - loss: 0.0309 - mae: 0.1552 - val_loss: 0.0245 - val_mae: 0.1522 - 102ms/epoch - 51ms/step\n",
            "Epoch 38/40\n",
            "2/2 - 0s - loss: 0.0167 - mae: 0.1154 - val_loss: 0.0081 - val_mae: 0.0818 - 101ms/epoch - 51ms/step\n",
            "Epoch 39/40\n",
            "2/2 - 0s - loss: 0.0148 - mae: 0.0998 - val_loss: 0.0019 - val_mae: 0.0342 - 120ms/epoch - 60ms/step\n",
            "Epoch 40/40\n",
            "2/2 - 0s - loss: 0.0193 - mae: 0.1020 - val_loss: 0.0016 - val_mae: 0.0345 - 104ms/epoch - 52ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70a1b8d400>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "mse, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUw7kjGvT9fx",
        "outputId": "e4edf8ee-8aa1-48fd-a595-2998cf84bc91"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.002, RMSE: 0.040, MAE: 0.035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "## row = asarray([5, 1, 1, 2, 2]).reshape((1, n_steps, 1))\n",
        "## print(\"row = %s\" %(row))\n",
        "## yhat = model.predict(row)\n",
        "## print('Predicted: %.3f' % (yhat))\n",
        "print(\"X_predict = %s\" %(X_predict))\n",
        "print(\"X_predict.shape = \", X_predict.shape)\n",
        "# print(\"After reshape, X_train.shape = %s, X_test.shape = %s, X_predict.shape = %s, y_train.shape = %s, y_test.shape = %s, y_predict.shape = %s\" %(X_train.shape, X_test.shape, X_predict.shape, y_train.shape, y_test.shape, y_predict.shape))\n",
        "yhat = model.predict(X_predict)\n",
        "print('Predicted: %.3f' % (yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGeHZkHoUFBk",
        "outputId": "e888d94d-a6d5-4fc2-c45e-922ff464e2d0"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_predict = [[[9.4308]\n",
            "  [9.4997]\n",
            "  [9.45  ]\n",
            "  [9.4264]\n",
            "  [9.372 ]\n",
            "  [9.4614]\n",
            "  [9.4346]\n",
            "  [9.4406]\n",
            "  [9.3731]\n",
            "  [9.4037]]]\n",
            "X_predict.shape =  (1, 10, 1)\n",
            "1/1 [==============================] - 1s 559ms/step\n",
            "Predicted: 9.416\n"
          ]
        }
      ]
    }
  ]
}
